{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyO3NRLdxCZO9bKG6np8+dyn",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "premium"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/thislis/XAI_Sentiment_Analysis/blob/main/test_multi_Bilstm.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "test\n",
        "\n",
        "build : Bi-LSTM, Multi classification"
      ],
      "metadata": {
        "id": "_aDrur8cHVE8"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "9VIsjyBbHNEg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8679a22d-84ae-4ac3-debf-77e1ffabf865"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "#google drive mount\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Mecab-ko download\n",
        "\n",
        "!git clone https://github.com/SOMJANG/Mecab-ko-for-Google-Colab.git\n",
        "%cd Mecab-ko-for-Google-Colab\n",
        "!bash install_mecab-ko_on_colab190912.sh"
      ],
      "metadata": {
        "id": "-viZ_IjAZNet",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c2ca8285-b699-460e-c836-11b6d8fb5a27"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Mecab-ko-for-Google-Colab'...\n",
            "remote: Enumerating objects: 115, done.\u001b[K\n",
            "remote: Counting objects: 100% (24/24), done.\u001b[K\n",
            "remote: Compressing objects: 100% (20/20), done.\u001b[K\n",
            "remote: Total 115 (delta 11), reused 10 (delta 3), pack-reused 91\u001b[K\n",
            "Receiving objects: 100% (115/115), 1.27 MiB | 9.50 MiB/s, done.\n",
            "Resolving deltas: 100% (50/50), done.\n",
            "/content/Mecab-ko-for-Google-Colab\n",
            "Installing konlpy.....\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting konlpy\n",
            "  Downloading konlpy-0.6.0-py2.py3-none-any.whl (19.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 19.4 MB 4.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.6 in /usr/local/lib/python3.7/dist-packages (from konlpy) (1.21.6)\n",
            "Collecting JPype1>=0.7.0\n",
            "  Downloading JPype1-1.4.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.whl (453 kB)\n",
            "\u001b[K     |████████████████████████████████| 453 kB 80.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: lxml>=4.1.0 in /usr/local/lib/python3.7/dist-packages (from konlpy) (4.9.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from JPype1>=0.7.0->konlpy) (4.1.1)\n",
            "Installing collected packages: JPype1, konlpy\n",
            "Successfully installed JPype1-1.4.0 konlpy-0.6.0\n",
            "Done\n",
            "Installing mecab-0.996-ko-0.9.2.tar.gz.....\n",
            "Downloading mecab-0.996-ko-0.9.2.tar.gz.......\n",
            "from https://bitbucket.org/eunjeon/mecab-ko/downloads/mecab-0.996-ko-0.9.2.tar.gz\n",
            "--2022-10-25 09:25:45--  https://bitbucket.org/eunjeon/mecab-ko/downloads/mecab-0.996-ko-0.9.2.tar.gz\n",
            "Resolving bitbucket.org (bitbucket.org)... 104.192.141.1, 2406:da00:ff00::22c5:2ef4, 2406:da00:ff00::22cd:e0db, ...\n",
            "Connecting to bitbucket.org (bitbucket.org)|104.192.141.1|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://bbuseruploads.s3.amazonaws.com/eunjeon/mecab-ko/downloads/mecab-0.996-ko-0.9.2.tar.gz?response-content-disposition=attachment%3B%20filename%3D%22mecab-0.996-ko-0.9.2.tar.gz%22&response-content-encoding=None&AWSAccessKeyId=ASIA6KOSE3BNFWR7AUJZ&Signature=rDifmv6Dg%2FHoZlEwzkxTSMD76Uo%3D&x-amz-security-token=FwoGZXIvYXdzEAsaDJh88ySoCBFgL4%2BRCiK%2BARZX6wiTyuxMnHoliDm%2FZYCw3KwdvouwMKMg2NS0fQtSq3a75Oqfz2L%2FijSQE1KUw3NetNdy3FTB9ax6nr6PdRs4yL7Je6%2BfPUMAK6V9s3yVv7nnAd9zqaqS8hN%2B8ShIRgAJy9d%2BWlG59Jv0WOz2j9lLEf%2BRRJUVQA6z7KxWYt%2FWOvr4eZA3Fbq%2B57cCA%2F4fWoY5%2B3aNV37sSWbz%2F5FOkrckqZ5D8Y6tNyBMUAcN%2BwUsmwVS%2B8JidmjWJPVY%2B6cojdLemgYyLSUMh85PmcOzeXHrY0%2FzeyGJGk35XwzGFuh%2Frg0w7EvcvEvu3G32JAXGQWDWQQ%3D%3D&Expires=1666691093 [following]\n",
            "--2022-10-25 09:25:45--  https://bbuseruploads.s3.amazonaws.com/eunjeon/mecab-ko/downloads/mecab-0.996-ko-0.9.2.tar.gz?response-content-disposition=attachment%3B%20filename%3D%22mecab-0.996-ko-0.9.2.tar.gz%22&response-content-encoding=None&AWSAccessKeyId=ASIA6KOSE3BNFWR7AUJZ&Signature=rDifmv6Dg%2FHoZlEwzkxTSMD76Uo%3D&x-amz-security-token=FwoGZXIvYXdzEAsaDJh88ySoCBFgL4%2BRCiK%2BARZX6wiTyuxMnHoliDm%2FZYCw3KwdvouwMKMg2NS0fQtSq3a75Oqfz2L%2FijSQE1KUw3NetNdy3FTB9ax6nr6PdRs4yL7Je6%2BfPUMAK6V9s3yVv7nnAd9zqaqS8hN%2B8ShIRgAJy9d%2BWlG59Jv0WOz2j9lLEf%2BRRJUVQA6z7KxWYt%2FWOvr4eZA3Fbq%2B57cCA%2F4fWoY5%2B3aNV37sSWbz%2F5FOkrckqZ5D8Y6tNyBMUAcN%2BwUsmwVS%2B8JidmjWJPVY%2B6cojdLemgYyLSUMh85PmcOzeXHrY0%2FzeyGJGk35XwzGFuh%2Frg0w7EvcvEvu3G32JAXGQWDWQQ%3D%3D&Expires=1666691093\n",
            "Resolving bbuseruploads.s3.amazonaws.com (bbuseruploads.s3.amazonaws.com)... 52.217.167.137\n",
            "Connecting to bbuseruploads.s3.amazonaws.com (bbuseruploads.s3.amazonaws.com)|52.217.167.137|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1414979 (1.3M) [application/x-tar]\n",
            "Saving to: ‘mecab-0.996-ko-0.9.2.tar.gz’\n",
            "\n",
            "mecab-0.996-ko-0.9. 100%[===================>]   1.35M  7.70MB/s    in 0.2s    \n",
            "\n",
            "2022-10-25 09:25:46 (7.70 MB/s) - ‘mecab-0.996-ko-0.9.2.tar.gz’ saved [1414979/1414979]\n",
            "\n",
            "Done\n",
            "Unpacking mecab-0.996-ko-0.9.2.tar.gz.......\n",
            "Done\n",
            "Change Directory to mecab-0.996-ko-0.9.2.......\n",
            "installing mecab-0.996-ko-0.9.2.tar.gz........\n",
            "configure\n",
            "make\n",
            "make check\n",
            "make install\n",
            "ldconfig\n",
            "Done\n",
            "Change Directory to /content\n",
            "Downloading mecab-ko-dic-2.1.1-20180720.tar.gz.......\n",
            "from https://bitbucket.org/eunjeon/mecab-ko-dic/downloads/mecab-ko-dic-2.1.1-20180720.tar.gz\n",
            "--2022-10-25 09:27:04--  https://bitbucket.org/eunjeon/mecab-ko-dic/downloads/mecab-ko-dic-2.1.1-20180720.tar.gz\n",
            "Resolving bitbucket.org (bitbucket.org)... 104.192.141.1, 2406:da00:ff00::3403:4be7, 2406:da00:ff00::22c5:2ef4, ...\n",
            "Connecting to bitbucket.org (bitbucket.org)|104.192.141.1|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://bbuseruploads.s3.amazonaws.com/a4fcd83e-34f1-454e-a6ac-c242c7d434d3/downloads/b5a0c703-7b64-45ed-a2d7-180e962710b6/mecab-ko-dic-2.1.1-20180720.tar.gz?response-content-disposition=attachment%3B%20filename%3D%22mecab-ko-dic-2.1.1-20180720.tar.gz%22&response-content-encoding=None&AWSAccessKeyId=ASIA6KOSE3BNKOKZG27E&Signature=wP4vTuZ60T2yq41dubXLcvJe5n8%3D&x-amz-security-token=FwoGZXIvYXdzEAsaDKlORJ3j%2BImkiwElvCK%2BAWy%2BCzV1hOx31%2FalZwKJ1kWHhXtpGd%2FF%2FVlVqNx03Lhr9CYhUBd195SOfzIzQ%2Frl1esXup7oCkaThGDjLFZZRfPJ%2BC4w681UZULNVOW7w1cAZpRPduE9VfB%2F5KrY8iAa25l%2F4RbP%2F%2FHAVdSUFpD%2F9Rd%2FnsuGKfPjmCEoZpAWOXZwv1%2BXkc5w2pIBi%2BWNkCytTcTZEt6kg3aKvWcg2GE4pVE4vhtjOw%2FaCyGROHxNdDZsn9kGQBhtbw1i0RcIdekosNfemgYyLez%2B9MTljz7Ue0kXXaSlvAO%2BYxD3Z0tb7Mnh0I8bTZn4maQ8evxV53i5jFblog%3D%3D&Expires=1666691768 [following]\n",
            "--2022-10-25 09:27:04--  https://bbuseruploads.s3.amazonaws.com/a4fcd83e-34f1-454e-a6ac-c242c7d434d3/downloads/b5a0c703-7b64-45ed-a2d7-180e962710b6/mecab-ko-dic-2.1.1-20180720.tar.gz?response-content-disposition=attachment%3B%20filename%3D%22mecab-ko-dic-2.1.1-20180720.tar.gz%22&response-content-encoding=None&AWSAccessKeyId=ASIA6KOSE3BNKOKZG27E&Signature=wP4vTuZ60T2yq41dubXLcvJe5n8%3D&x-amz-security-token=FwoGZXIvYXdzEAsaDKlORJ3j%2BImkiwElvCK%2BAWy%2BCzV1hOx31%2FalZwKJ1kWHhXtpGd%2FF%2FVlVqNx03Lhr9CYhUBd195SOfzIzQ%2Frl1esXup7oCkaThGDjLFZZRfPJ%2BC4w681UZULNVOW7w1cAZpRPduE9VfB%2F5KrY8iAa25l%2F4RbP%2F%2FHAVdSUFpD%2F9Rd%2FnsuGKfPjmCEoZpAWOXZwv1%2BXkc5w2pIBi%2BWNkCytTcTZEt6kg3aKvWcg2GE4pVE4vhtjOw%2FaCyGROHxNdDZsn9kGQBhtbw1i0RcIdekosNfemgYyLez%2B9MTljz7Ue0kXXaSlvAO%2BYxD3Z0tb7Mnh0I8bTZn4maQ8evxV53i5jFblog%3D%3D&Expires=1666691768\n",
            "Resolving bbuseruploads.s3.amazonaws.com (bbuseruploads.s3.amazonaws.com)... 54.231.162.169\n",
            "Connecting to bbuseruploads.s3.amazonaws.com (bbuseruploads.s3.amazonaws.com)|54.231.162.169|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 49775061 (47M) [application/x-tar]\n",
            "Saving to: ‘mecab-ko-dic-2.1.1-20180720.tar.gz’\n",
            "\n",
            "mecab-ko-dic-2.1.1- 100%[===================>]  47.47M  66.6MB/s    in 0.7s    \n",
            "\n",
            "2022-10-25 09:27:05 (66.6 MB/s) - ‘mecab-ko-dic-2.1.1-20180720.tar.gz’ saved [49775061/49775061]\n",
            "\n",
            "Done\n",
            "Unpacking  mecab-ko-dic-2.1.1-20180720.tar.gz.......\n",
            "Done\n",
            "Change Directory to mecab-ko-dic-2.1.1-20180720\n",
            "Done\n",
            "installing........\n",
            "configure\n",
            "make\n",
            "make install\n",
            "apt-get update\n",
            "apt-get upgrade\n",
            "apt install curl\n",
            "apt install git\n",
            "bash <(curl -s https://raw.githubusercontent.com/konlpy/konlpy/master/scripts/mecab.sh)\n",
            "Done\n",
            "Successfully Installed\n",
            "Now you can use Mecab\n",
            "from konlpy.tag import Mecab\n",
            "mecab = Mecab()\n",
            "사용자 사전 추가 방법 : https://bit.ly/3k0ZH53\n",
            "NameError: name 'Tagger' is not defined 오류 발생 시 런타임을 재실행 해주세요\n",
            "블로그에 해결 방법을 남겨주신 tana님 감사합니다.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#import modules\n",
        "\n",
        "#test data reading and processing\n",
        "import re, os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from collections import Counter\n",
        "from konlpy.tag import Mecab\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "import tensorflow as tf\n",
        "\n",
        "#modeling\n",
        "from tensorflow.keras.layers import Embedding, Dense, LSTM, Bidirectional\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.models import load_model\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import keras.backend as K"
      ],
      "metadata": {
        "id": "vaHha3Z6r4sM"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#data loading\n",
        "\n",
        "data_file_path = \"/content/drive/Shareddrives/R&E/dataset\"\n",
        "sentiment_file_list = os.listdir(data_file_path)\n",
        "train_data = pd.DataFrame(columns = ['감정', '문장'])\n",
        "\n",
        "for path in sentiment_file_list:\n",
        "  train_add = pd.read_csv(data_file_path + '/' + path)\n",
        "  train_add.dropna()\n",
        "  train_data = pd.concat([train_data, train_add], ignore_index = True)\n",
        "\n",
        "train_data.drop_duplicates(subset=['문장'], inplace=True)#delete overlap data\n",
        "\n",
        "test_data = pd.read_csv(data_file_path + '/test_dataset.csv', names=['감정', '문장'], skiprows=1)\n",
        "test_data.drop_duplicates(subset=['문장'], inplace=True) #delete overlap data"
      ],
      "metadata": {
        "id": "SjhcYsnzZTsR"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#regex, blank to Null\n",
        "\n",
        "train_data['문장'] = train_data['문장'].str.replace(\"[^ㄱ-ㅎㅏ-ㅣ가-힣 ]\",\"\")\n",
        "train_data['문장'].replace('', np.nan, inplace=True)\n",
        "test_data['문장'] = test_data['문장'].str.replace(\"[^ㄱ-ㅎㅏ-ㅣ가-힣 ]\",\"\")\n",
        "test_data['문장'].replace('', np.nan, inplace=True)"
      ],
      "metadata": {
        "id": "HIV6hLX8fPpA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1b92590f-21d5-48a4-c83f-dac0482e835e"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:3: FutureWarning: The default value of regex will change from True to False in a future version.\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:5: FutureWarning: The default value of regex will change from True to False in a future version.\n",
            "  \"\"\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#def stopword\n",
        "\n",
        "stopwords = ['도', '는', '다', '의', '가', '이', '은', '한', '에', '하', '고', '을', '를', '인', '듯', '과', '와', '네', '들', '듯', '지', '임', '게', '만', '되', '음', '면']"
      ],
      "metadata": {
        "id": "C_kQWYSJfhgL"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#def function - sentiment to int\n",
        "\n",
        "def toint(text):\n",
        "  if text == \"분노\":\n",
        "    return 0\n",
        "\n",
        "  elif text == \"불안\":\n",
        "    return 1\n",
        "\n",
        "  elif text == \"당황\":\n",
        "    return 2\n",
        "\n",
        "  elif text == \"기쁨\":\n",
        "    return 3\n",
        "\n",
        "  elif text == \"상처\":\n",
        "    return 4\n",
        "\n",
        "  elif text == \"슬픔\":\n",
        "    return 5"
      ],
      "metadata": {
        "id": "iWBbJPPOfykW"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#sentiment to int\n",
        "\n",
        "train_data['감정'] = train_data['감정'].apply(toint)\n",
        "test_data['감정'] = test_data['감정'].apply(toint)\n",
        "\n",
        "print(train_data)\n",
        "print(test_data)"
      ],
      "metadata": {
        "id": "HUBI_27znlVj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b2f70b65-c925-4d46-dd56-d237e855e5f7"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "        감정                                                 문장  Unnamed: 0\n",
            "0        3                           아내가 드디어 출산하게 되어서 정말 신이 나         0.0\n",
            "1        3        재취업이 돼서 받게 된 첫 월급으로 온 가족이 외식을 할 예정이야 너무 행복해         3.0\n",
            "2        3                        빚을 드디어 다 갚게 되어서 이제야 안도감이 들어         4.0\n",
            "3        3        남편이 죽기 전에 손자들 얼굴 보고 싶다고 했는데 다행히 늦지 않아서 안도했어        14.0\n",
            "4        3                                  친구가 사준 로또가 당첨이 됐어        23.0\n",
            "...     ..                                                ...         ...\n",
            "114001   5               무기력한 기분을 떨치고 적극적으로 반항하고 주위에 도움을 청해볼래     11833.0\n",
            "114002   5                  생활이 좀 빠듯하네 이 정도로 적게 받을 줄 몰랐는데 말이야     11842.0\n",
            "114003   5  아내에게 가서 솔직하게 내 마음을 말해야겠어 다음부터는 뭐든 말해주고 의논했으면 좋겠다고     11857.0\n",
            "114004   5                          친구들을 만나고 싶어도 만날 수 없어서 속상해     11862.0\n",
            "114005   5                 친한 친구는 아니지만 젊은 나이에 사망해서 더 마음이 비통하네     11867.0\n",
            "\n",
            "[108728 rows x 3 columns]\n",
            "       감정                                                 문장\n",
            "9       3                           이 업무는 하루 만에 끝낼 수 있을 것 같아\n",
            "10      3          나 대학에 쉽게 갈 수 있을 것 같아 학원 선생님들 실력이 정말 믿을 만해\n",
            "16      3                             심혈을 기울여 작성한 기획안이 통과되었어\n",
            "21      3                               좋아하던 선배에게 어제 고백을 받았어\n",
            "26      3            오늘 반장 선거에서 내가 반장이 됐어 친구들이 날 믿어줘서 너무 고맙다\n",
            "...    ..                                                ...\n",
            "11833   5               무기력한 기분을 떨치고 적극적으로 반항하고 주위에 도움을 청해볼래\n",
            "11842   5                  생활이 좀 빠듯하네 이 정도로 적게 받을 줄 몰랐는데 말이야\n",
            "11857   5  아내에게 가서 솔직하게 내 마음을 말해야겠어 다음부터는 뭐든 말해주고 의논했으면 좋겠다고\n",
            "11862   5                          친구들을 만나고 싶어도 만날 수 없어서 속상해\n",
            "11867   5                 친한 친구는 아니지만 젊은 나이에 사망해서 더 마음이 비통하네\n",
            "\n",
            "[11932 rows x 2 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Train Data Labels\n",
        "train_data[\"감정\"] = train_data[\"감정\"].astype('category')\n",
        "train_data[\"emotion_label\"] = train_data[\"감정\"].cat.codes\n",
        "train_features, train_labels = train_data['문장'], tf.one_hot(train_data[\"emotion_label\"], 6)\n",
        "\n",
        "# Test Data Labels\n",
        "test_data[\"감정\"] = test_data[\"감정\"].astype('category')\n",
        "test_data[\"emotion_label\"] = test_data[\"감정\"].cat.codes\n",
        "test_features, test_labels = test_data['문장'], tf.one_hot(test_data[\"emotion_label\"], 6)"
      ],
      "metadata": {
        "id": "kQeYAu1q-9-L"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#tokenizing\n",
        "\n",
        "mecab = Mecab() \n",
        "\n",
        "train_data['tokenized'] = train_data['문장'].apply(mecab.morphs)\n",
        "train_data['tokenized'] = train_data['tokenized'].apply(lambda x: [item for item in x if item not in stopwords])\n",
        "test_data['tokenized'] = test_data['문장'].apply(mecab.morphs)\n",
        "test_data['tokenized'] = test_data['tokenized'].apply(lambda x: [item for item in x if item not in stopwords])"
      ],
      "metadata": {
        "id": "4BIRptVdfqbF"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#tokenized seq-> X\n",
        "\n",
        "X_train = train_data['tokenized'].values\n",
        "X_test= test_data['tokenized'].values"
      ],
      "metadata": {
        "id": "MWQajlPonFQz"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#max length for LSTM\n",
        "\n",
        "max_len = 35"
      ],
      "metadata": {
        "id": "FEOZCUGXn5xs"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#F1-score\n",
        "\n",
        "def get_f1(y_true, y_pred): #taken from old keras source code\n",
        "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
        "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
        "    precision = true_positives / (predicted_positives + K.epsilon())\n",
        "    recall = true_positives / (possible_positives + K.epsilon())\n",
        "    f1_val = 2*(precision*recall)/(precision+recall+K.epsilon())\n",
        "    return f1_val"
      ],
      "metadata": {
        "id": "JV411SfHXtR3"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#model fitting\n",
        "\n",
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(X_train)\n",
        "\n",
        "threshold = 2\n",
        "total_cnt = len(tokenizer.word_index) #word count\n",
        "rare_cnt = 0 #count word; frequency of appearance < threshold\n",
        "total_freq = 0 #sum freq in all train data\n",
        "rare_freq = 0 #sum freq in train data; frequency of appearance < threshold\n",
        "\n",
        "#(word, frequency) ->key and value\n",
        "for key, value in tokenizer.word_counts.items():\n",
        "    total_freq = total_freq + value\n",
        "    if(value < threshold):\n",
        "        rare_cnt = rare_cnt + 1\n",
        "        rare_freq = rare_freq + value\n",
        "\n",
        "vocab_size = total_cnt - rare_cnt + 2\n",
        "\n",
        "tokenizer = Tokenizer(vocab_size, oov_token = 'OOV') \n",
        "tokenizer.fit_on_texts(X_train)\n",
        "X_train = tokenizer.texts_to_sequences(X_train)\n",
        "X_test = tokenizer.texts_to_sequences(X_test)\n",
        "\n",
        "X_train = pad_sequences(X_train, maxlen=max_len)\n",
        "X_test = pad_sequences(X_test, maxlen=max_len)\n",
        "\n",
        "embedding_dim = 100\n",
        "hidden_units = 128\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Embedding(vocab_size, embedding_dim))\n",
        "model.add(Bidirectional(LSTM(hidden_units))) # Bidirectional LSTM\n",
        "model.add(Dense(6, activation='softmax'))\n",
        "\n",
        "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=4)\n",
        "mc = ModelCheckpoint('best_model.h5', monitor='val_acc', mode='max', verbose=1, save_best_only=True)\n",
        "\n",
        "model.compile(optimizer='rmsprop',loss='categorical_crossentropy',\n",
        "              metrics=['acc',tf.keras.metrics.Recall(), tf.keras.metrics.Precision(), get_f1])\n",
        "history = model.fit(X_train, train_labels, epochs=15, callbacks=[es, mc], batch_size=128, validation_split=0.2)"
      ],
      "metadata": {
        "id": "5JuhZtxvoC9A",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ed9baf72-8c8b-4f02-f500-86933af6a583"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15\n",
            "676/680 [============================>.] - ETA: 0s - loss: 1.3371 - acc: 0.4782 - recall: 0.2469 - precision: 0.7743 - get_f1: 0.3584\n",
            "Epoch 1: val_acc improved from -inf to 0.32484, saving model to best_model.h5\n",
            "680/680 [==============================] - 20s 13ms/step - loss: 1.3364 - acc: 0.4785 - recall: 0.2475 - precision: 0.7744 - get_f1: 0.3592 - val_loss: 2.1877 - val_acc: 0.3248 - val_recall: 0.2131 - val_precision: 0.6460 - val_get_f1: 0.2943\n",
            "Epoch 2/15\n",
            "676/680 [============================>.] - ETA: 0s - loss: 1.1670 - acc: 0.5535 - recall: 0.3653 - precision: 0.7724 - get_f1: 0.4951\n",
            "Epoch 2: val_acc improved from 0.32484 to 0.34195, saving model to best_model.h5\n",
            "680/680 [==============================] - 8s 12ms/step - loss: 1.1671 - acc: 0.5535 - recall: 0.3653 - precision: 0.7724 - get_f1: 0.4950 - val_loss: 2.1256 - val_acc: 0.3419 - val_recall: 0.2284 - val_precision: 0.6591 - val_get_f1: 0.3164\n",
            "Epoch 3/15\n",
            "680/680 [==============================] - ETA: 0s - loss: 1.1187 - acc: 0.5727 - recall: 0.3934 - precision: 0.7702 - get_f1: 0.5198\n",
            "Epoch 3: val_acc did not improve from 0.34195\n",
            "680/680 [==============================] - 8s 12ms/step - loss: 1.1187 - acc: 0.5727 - recall: 0.3934 - precision: 0.7702 - get_f1: 0.5198 - val_loss: 2.3421 - val_acc: 0.3392 - val_recall: 0.2432 - val_precision: 0.5929 - val_get_f1: 0.3200\n",
            "Epoch 4/15\n",
            "680/680 [==============================] - ETA: 0s - loss: 1.0850 - acc: 0.5887 - recall: 0.4168 - precision: 0.7710 - get_f1: 0.5403\n",
            "Epoch 4: val_acc did not improve from 0.34195\n",
            "680/680 [==============================] - 8s 12ms/step - loss: 1.0850 - acc: 0.5887 - recall: 0.4168 - precision: 0.7710 - get_f1: 0.5403 - val_loss: 2.4824 - val_acc: 0.3318 - val_recall: 0.2394 - val_precision: 0.5579 - val_get_f1: 0.3123\n",
            "Epoch 5/15\n",
            "678/680 [============================>.] - ETA: 0s - loss: 1.0537 - acc: 0.6002 - recall: 0.4355 - precision: 0.7761 - get_f1: 0.5570\n",
            "Epoch 5: val_acc improved from 0.34195 to 0.34636, saving model to best_model.h5\n",
            "680/680 [==============================] - 8s 12ms/step - loss: 1.0539 - acc: 0.6001 - recall: 0.4356 - precision: 0.7758 - get_f1: 0.5570 - val_loss: 2.3642 - val_acc: 0.3464 - val_recall: 0.2545 - val_precision: 0.5837 - val_get_f1: 0.3314\n",
            "Epoch 6/15\n",
            "680/680 [==============================] - ETA: 0s - loss: 1.0255 - acc: 0.6108 - recall: 0.4525 - precision: 0.7814 - get_f1: 0.5723\n",
            "Epoch 6: val_acc did not improve from 0.34636\n",
            "680/680 [==============================] - 8s 12ms/step - loss: 1.0255 - acc: 0.6108 - recall: 0.4525 - precision: 0.7814 - get_f1: 0.5723 - val_loss: 2.4114 - val_acc: 0.3440 - val_recall: 0.2540 - val_precision: 0.5486 - val_get_f1: 0.3248\n",
            "Epoch 6: early stopping\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loaded_model = load_model('best_model.h5', custom_objects={'get_f1' : get_f1})\n",
        "loaded_model.evaluate(X_test, test_labels)"
      ],
      "metadata": {
        "id": "VMK3tkGPR5lK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b3e14eae-7e4d-4029-d12f-2af16faead9e"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "373/373 [==============================] - 3s 5ms/step - loss: 1.4216 - acc: 0.5075 - recall: 0.3693 - precision: 0.7081 - get_f1: 0.4622\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1.421587347984314,\n",
              " 0.5074589252471924,\n",
              " 0.36934295296669006,\n",
              " 0.7080655694007874,\n",
              " 0.4621593952178955]"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    }
  ]
}